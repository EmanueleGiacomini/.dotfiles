# pegasus-vpr

Resources for Tommaso Pietrosanti

General resources + a good tutorial for getting into the problem

1. [Awesome Visual Place Recognition](https://github.com/gmberton/awesome-Visual-Place-Recognition)
2. [Visual Place Recognition: A Tutorial](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10261441)

Learning based methodologies which could be cool to look into:

1. [Place recognition survey: An update on deep learning approaches](https://arxiv.org/pdf/2106.10458)
2. [LunarLoc: Segment-Based Global Localization on the Moon](https://arxiv.org/abs/2506.16940v1)
3. [NetVLAD: CNN Architecture for Weakly Supervised Place Recognition](https://openaccess.thecvf.com/content_cvpr_2016/html/Arandjelovic_NetVLAD_CNN_Architecture_CVPR_2016_paper.html)

The dataset shown on LunarLoc could be interesting for some simulation-based tests.

Additional datasets which could be of interest for real scenarios:

1. [GrandTour Dataset](https://grand-tour.leggedrobotics.com/) for data captured by a quadruped robot (motion-law)
2. [TAIL SLAM dataset](https://tailrobot.github.io/) very hard, quadruped SLAM trajectories on unstructured data (really close to our scenario).

## Suggestions

- Take it easy, don't go immediately too deep into algorithms or techniques. Take time for smaller Proof Of Concept (POC)s
- **Very Important** Keep track of your notes and progresses using a Google Slides presentation (PowerPoint works too). **This is extremely important, even if often overlooked**. Keep relevant images, notes, equations, etc. It will make debugging and discussion phases 1000% faster and more informative.

- Start from `Visual Place Recognition: A Tutorial` to grasp the problem of VPR, we are rather interested at Online VPR, but get used to other methodologies too.
- Look at `LunarLoc` and possibly expand research from linked papers.
- If you need to test out VPR to get used to it, you can try some simpler datasets (i.e., KITTI or if you are unsure, just ask us)

- If you need resources or clarifications, ask us!
